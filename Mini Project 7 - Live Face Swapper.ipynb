{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d8fce3c4f060>:167: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(s == \"no faces\"):\n",
      "<ipython-input-7-d8fce3c4f060>:170: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  elif(s == \"too many faces\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "# not fully understood\n",
    "\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"D:/Computer_Vision_Recap/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "predictor_path = \"D:/Computer_Vision_Recap/shape_predictor_68_face_landmarks.dat\"\n",
    "scale_factor = 1\n",
    "feather_amount = 11\n",
    "\n",
    "# facial landmarks\n",
    "face_points = list(range(17, 68))\n",
    "mouth_points = list(range(48, 61))\n",
    "right_brow_points = list(range(17, 22))\n",
    "left_brow_points = list(range(22, 27))\n",
    "right_eye_points = list(range(36, 42))\n",
    "left_eye_points = list(range(42, 48))\n",
    "nose_points = list(range(27, 35))\n",
    "jaw_points = list(range(0, 17))\n",
    "\n",
    "\n",
    "# points to line up im1 and im2\n",
    "allign_points = (left_brow_points + right_brow_points + left_eye_points + \n",
    "             right_eye_points + nose_points + mouth_points)\n",
    "\n",
    "# points from im2 to be overlaid on im1\n",
    "overlay_points = [\n",
    "    left_eye_points + right_eye_points + left_brow_points + right_brow_points + \n",
    "    nose_points + mouth_points\n",
    "]\n",
    "\n",
    "\n",
    "color_correct_blur_frac = 0.6            # amount of blut to use during color correction\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "\n",
    "def get_facial_landmarks(image, dlibOn):\n",
    "    if(dlibOn == True):\n",
    "        rects = detector(image, 1)          # gets ROI of the facial landmark\n",
    "        if(len(rects) > 1):\n",
    "            return \"too many faces\"\n",
    "        if(len(rects)) == 0:\n",
    "            return \"no faces\"\n",
    "        # returns reformatted array for annot landmarks func\n",
    "        return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n",
    "    \n",
    "    else:\n",
    "        rects = face_classifier.detectMultiScale(image, 1.3, 5)\n",
    "        if(len(rects) > 1):\n",
    "            return \"too many faces\"\n",
    "        if(len(rects) == 0):\n",
    "            return \"no faces\"\n",
    "        # returns reformatted array for annot landmarks func\n",
    "        x1, y1, x2, y2 = rects[0]\n",
    "        rect = dlib.rectangle(x1, y1, x1+x2 , y1+y2)\n",
    "        return np.matrix([[p.x, p.y] for p in predictor(image, rects).parts()])\n",
    "\n",
    "def annotate_landmarks(image, landmarks):\n",
    "    # func, numbers the detected landmarks\n",
    "    image = image.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0,0], point[0,1])\n",
    "        cv2.putText(image, str(idx), pos,\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 0.4, (255, 0, 0), 1)\n",
    "        cv2.circle(image, pos, 3, (0,0, 255), 1)\n",
    "    return image\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color = color)\n",
    "    \n",
    "def get_face_mask(im, landmarks):\n",
    "    im = np.zeros(im.shape[:2], dtype = np.float64)\n",
    "    \n",
    "    for group in overlay_points:\n",
    "        draw_convex_hull(im, landmarks[group], color = 1)\n",
    "        \n",
    "    im = np.array([im, im, im]).transpose((1, 2, 0))\n",
    "    \n",
    "    im = (cv2.GaussianBlur(im, (feather_amount, feather_amount), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (feather_amount, feather_amount), 0)\n",
    "    return im\n",
    "\n",
    "\n",
    "def transformation_from_points(points1, points2):\n",
    "    \"\"\"\n",
    "    ret affine transformation matrix for warping op of image 1 and image 2\n",
    "    using procustes method\n",
    "    \"\"\"\n",
    "    points1 = points1.astype(np.float64)\n",
    "    points2 = points2.astype(np.float64)\n",
    "\n",
    "    c1 = np.mean(points1, axis = 0)\n",
    "    c2 = np.mean(points2, axis = 0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "    \n",
    "    s1 = np.std(points1)\n",
    "    s2 = np.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(points1.T * points2)\n",
    "    R = (U * Vt).T\n",
    "    \n",
    "    return np.vstack([\n",
    "        np.hstack(((s2 / s1) * R,\n",
    "                  c2.T - (s2 / s1) * R * c1.T)),\n",
    "        np.matrix([0., 0., 1.])\n",
    "    ])\n",
    "\n",
    "def read_im_and_landmarks(image):\n",
    "    \"\"\"\n",
    "    func reads and resizes image for faster computationa and gets landmarks\n",
    "    returns image along with its detected landmarks\n",
    "    \"\"\"\n",
    "    im = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, None, fx = 0.35, fy = 0.35, interpolation = cv2.INTER_LINEAR)\n",
    "    im = cv2.resize(im, (im.shape[1] * scale_factor, im.shape[0] * scale_factor))\n",
    "    \n",
    "    s = get_facial_landmarks(im, dlibOn)\n",
    "    return im, s\n",
    "\n",
    "def warp_im(image, M, dshape):\n",
    "    output_im = np.zeros(dshape, dtype=image.dtype)\n",
    "    # does the warp opp and the borders is made transparent and ret the result\n",
    "    cv2.warpAffine(image,\n",
    "                  M[:2],\n",
    "                  (dshape[1], dshape[0]),\n",
    "                  dst = output_im,\n",
    "                  borderMode = cv2.BORDER_TRANSPARENT,\n",
    "                  flags = cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    # does the color correction & blurring operations\n",
    "    blur_amount = color_correct_blur_frac * np.linalg.norm(\n",
    "            np.mean(landmarks1[left_eye_points], axis = 0) - \n",
    "            np.mean(landmarks1[right_eye_points], axis = 0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "    \n",
    "    # avoids zero div Xception\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "    \n",
    "    return (im2.astype(np.float64) * im1_blur.astype(np.float64) / \n",
    "            im2_blur.astype(np.float64))\n",
    "    \n",
    "    \n",
    "def face_swapper(image, image_to_swap):\n",
    "    \"\"\"\n",
    "    uses above functions here and swaps and display image\n",
    "    image = LiveFeed and image_to_swap is image for swapping\n",
    "    \"\"\"\n",
    "    s = get_facial_landmarks(image, True)\n",
    "    \n",
    "    if(s == \"no faces\"):\n",
    "        print(\"No face detected\")\n",
    "        return image\n",
    "    elif(s == \"too many faces\"):\n",
    "        print(\"Too many faces detected\")\n",
    "        return image\n",
    "    \n",
    "    im1, landmarks1 = image, s\n",
    "    im2, landmarks2 = read_im_and_landmarks(image_to_swap)\n",
    "    \n",
    "    M = transformation_from_points(landmarks1[allign_points], landmarks2[allign_points])\n",
    "    \n",
    "    mask = get_face_mask(im2, landmarks2)\n",
    "    warped_mask = warp_im(mask, M, im1.shape)\n",
    "    combined_mask = np.max([get_face_mask(im1, landmarks1), warped_mask],\n",
    "                          axis = 0)\n",
    "    \n",
    "    warped_im2 = warp_im(im2, M, im1.shape)\n",
    "    warped_color_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
    "    \n",
    "    output_im = im1 * (1.0 - combined_mask) + warped_color_corrected_im2 * combined_mask\n",
    "    \n",
    "    cv2.imwrite(\"Swapped_face_test.jpg\", output_im)\n",
    "    image = cv2.imread(\"Swapped_face_test.jpg\")\n",
    "    \n",
    "    frame = cv2.resize(image, None, fx= 1.5, fy=1.5, interpolation = cv2.INTER_LINEAR)\n",
    "    return image\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# filter image is image swapper, and dlibOn means use dlib for detecting face\n",
    "# else use HaarCascade classifier\n",
    "filter_image = \"D:/Computer_Vision_Recap/images/Hillary.jpg\"\n",
    "dlibOn = True\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # reduce frame image for faster computation\n",
    "    frame = cv2.resize(frame, None, fx=0.75, fy = 0.75, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2.imshow(\"Live face Swapper\", face_swapper(frame, filter_image))\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
