{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# def range of yellow color HSV color space\n",
    "lower_yellow = np.array([20, 0, 0])\n",
    "upper_yelllow = np.array([41,255, 255])\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # get hsv colorspace image\n",
    "    hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # gets mask of only color in the specified color Range\n",
    "    mask = cv2.inRange(hsv_img, lower_yellow, upper_yelllow)\n",
    "    \n",
    "    # bitwise AND opp on mask and original frame and ret an image\n",
    "    result = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "    \n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"Filtered Color only\", result)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guassian Mixture-Based Background2\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"D:/Computer_Vision_Recap/images/Walking.avi\")\n",
    "\n",
    "# init background subtractor\n",
    "foreground_background = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # apply background subtractor to get foreground mask\n",
    "    foreground_mask = foreground_background.apply(frame)\n",
    "    \n",
    "    cv2.imshow(\"Guassian Mixture-Based Background\", foreground_mask)\n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BackGround Subtraction KNN #####\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"D:/Computer_Vision_Recap/images/Walking.avi\")\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "foreground_background = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    foreground_mask = foreground_background.apply(frame)\n",
    "    foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    cv2.imshow(\"Background sub KNN\", foreground_mask)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FOREGROUND SUBTRACTION ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "avg = np.float32(frame)\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # 0.01 is weight of image, looks at movement in frame and accumulates\n",
    "    # weights for things not moving\n",
    "    cv2.accumulateWeighted(frame, avg, 0.01)\n",
    "    \n",
    "    # conversion to show to user\n",
    "    background = cv2.convertScaleAbs(avg)\n",
    "    \n",
    "    cv2.imshow(\"Input\", frame)\n",
    "    cv2.imshow(\"Foreground subtraction\", background)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MeanShift Object Tracking #####\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# setsup default location of tracking window\n",
    "y1, y2, x1, x2 = 200, 150, 500, 178\n",
    "track_window = (x1, y1, x2, y2)\n",
    "\n",
    "# crops ROI for tracking\n",
    "roi = frame[y1:y1+y2, x1:x1+x2]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# creates mask within hsv color space range\n",
    "lower_yellow = np.array([20, 0, 0])\n",
    "upper_yelllow = np.array([43,255, 255])\n",
    "mask = cv2.inRange(hsv_roi, lower_yellow, upper_yelllow)\n",
    "\n",
    "# gets color hist of ROI which is needed to normalize values btw 0 - 255\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [50], [0, 50])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "\"\"\"\n",
    "setsup termination criteria, i.e stop calc when centroid shift after ten\n",
    "iteration and the centroid doesn't move by @ least 1 pixel\n",
    "\"\"\"\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if ret:      # true when reading succesfull\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # GETS hist back propagation i.e prob of a pixel valu and\n",
    "        # is needed by meanashift\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 50], 1)\n",
    "        \n",
    "        # apply meanshift to get new loc\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        x1, y1, x2, y2 = track_window\n",
    "        img_2 = cv2.rectangle(frame, (x1, y1), (x1+x2, y1+y2), 255, 2)\n",
    "        cv2.imshow(\"MeanShift Tracking\", img_2)\n",
    "        \n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CamShift Object Tracking ###\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# setsup default location of tracking window\n",
    "y1, y2, x1, x2 = 200, 150, 500, 178\n",
    "track_window = (x1, y1, x2, y2)\n",
    "\n",
    "# crops ROI for tracking\n",
    "roi = frame[y1:y1+y2, x1:x1+x2]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# creates mask within hsv color space range\n",
    "lower_yellow = np.array([20, 0, 0])\n",
    "upper_yelllow = np.array([43,255, 255])\n",
    "mask = cv2.inRange(hsv_roi, lower_yellow, upper_yelllow)\n",
    "\n",
    "# gets color hist of ROI which is needed to normalize values btw 0 - 255\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [50], [0, 50])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "\"\"\"\n",
    "setsup termination criteria, i.e stop calc when centroid shift after ten\n",
    "iteration and the centroid doesn't move by @ least 1 pixel\n",
    "\"\"\"\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if ret:      # true when reading succesfull\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # GETS hist back propagation i.e prob of a pixel value and\n",
    "        # is needed by camshift\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 50], 1)\n",
    "        \n",
    "        # apply camShift to get new loc\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # draw new tracking window on frame and use PolyLines to rep adaptive Box\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img_2 = cv2.polylines(frame, [pts], True, 255, 2)\n",
    "        cv2.imshow(\"CamShfit Object Tracking\", img_2)\n",
    "        \n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Optical Flow Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c1174819d454>:46: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  mask = cv2.line(mask, (a,b), (c,d), color[i].tolist(), 2)\n",
      "<ipython-input-3-c1174819d454>:47: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  frame = cv2.circle(frame, (a,b), 5, color[i].tolist(),-1)\n"
     ]
    }
   ],
   "source": [
    "### Lucas Kanade OpticalFlow(only keypoints)###\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"D:/Computer_Vision_Recap/images/Walking.avi\")\n",
    "\n",
    "# sets params for shiTomasi corner detection\n",
    "feature_params = dict(maxCorners = 100, qualityLevel = 0.3,\n",
    "                     minDistance = 7, blockSize = 7)\n",
    "\n",
    "# sets params for LK opticalFlow\n",
    "lucas_kanade_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors for trailing image movement in frame\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find init corners in it\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    new_corners, status, errors = cv2.calcOpticalFlowPyrLK(prev_gray, \n",
    "                                                           frame_gray, \n",
    "                                                           prev_corners, \n",
    "                                                           None, \n",
    "                                                           **lucas_kanade_params)\n",
    "\n",
    "    # Select and store good points(new and old corners)\n",
    "    good_new = new_corners[status==1]\n",
    "    good_old = prev_corners[status==1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b), (c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a,b), 5, color[i].tolist(),-1)\n",
    "        \n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    # Show Optical Flow\n",
    "    cv2.imshow('Optical Flow - Lucas-Kanade',img)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prev_corners = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dense Optical Flow(Slower than LK Optical Flow) ###\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"D:/Computer_Vision_Recap/images/Walking.avi\")\n",
    "\n",
    "# Get first frame\n",
    "ret, first_frame = cap.read()\n",
    "previous_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(first_frame)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Computes the dense optical flow using the Gunnar Farneback’s algorithm\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_gray, next, \n",
    "                                        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # use flow to calculate the magnitude (speed) and angle of motion\n",
    "    # use these values to calculate the color to reflect speed and angle\n",
    "    magnitude, angle = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = angle * (180 / (np.pi/2))\n",
    "    hsv[...,2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    final = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    \n",
    "    cv2.imshow('Dense Optical Flow', final)\n",
    "    if cv2.waitKey(1) == 13: \n",
    "        break\n",
    "    \n",
    "    # Store current image as previous image\n",
    "    previous_gray = next\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
