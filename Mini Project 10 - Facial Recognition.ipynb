{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face Collection and Xtraction complete\n"
     ]
    }
   ],
   "source": [
    "###### DATA COLLECTION ##########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_clasifier = cv2.CascadeClassifier(\"D:/Computer_Vision_Recap/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "def face_extractor(image):\n",
    "    # func detects and xtract faces for training and if no face returns image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.Canny(gray,20, 120)\n",
    "    faces = face_clasifier.detectMultiScale(image, 1.3, 5)\n",
    "    if(len(faces) == 0):\n",
    "        return None\n",
    "    # crops all faces found\n",
    "    for (x1, y1, x2, y2) in faces:\n",
    "        cropped_face = image[y1:y1+y2, x1:x1+x2]\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# collects n_samples of face from webcam\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # saves file in specified loc\n",
    "        file_path_name = \"D:/Computer_Vision_Recap/faces/user/\" + str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_path_name, face)\n",
    "        \n",
    "        # displays live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, \n",
    "                   (180, 0, 0), 2)\n",
    "        cv2.imshow(\"Face Xtraction Process\", face)\n",
    "        if(count == 120):\n",
    "            break\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Face Collection and Xtraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been trained succesfully\n"
     ]
    }
   ],
   "source": [
    "##### MODEL TRAINING #####\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# gets training data from spec dir\n",
    "data_path = \"D:/Computer_Vision_Recap/faces/user/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "training_data, labels = [], []\n",
    "\n",
    "# open training images in datapath and create np array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]     # ref to an image \n",
    "    images = cv2.imread(image_path, 0)\n",
    "    training_data.append(np.asarray(images, np.uint8))\n",
    "    labels.append(i)\n",
    "    \n",
    "# create np array for labels\n",
    "labels = np.asarray(labels, np.int32)\n",
    "\n",
    "# init facial recog model\n",
    "face_recog_model = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recog_model.train(np.asarray(training_data), np.asarray(labels))\n",
    "print(\"Model has been trained succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Testing Facial Recognition ######\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"D:/Computer_Vision_Recap/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_detector(image, size = 0.5):\n",
    "    # func detects faces from webcam for classification\n",
    "    # and ret the image(rect drawn) and the roi of interest(the face)\n",
    "    gray_image = cv2.cvtColor(image,  cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.GaussianBlur(gray_image, (3,3), 0)\n",
    "    faces = face_classifier.detectMultiScale(gray_image, 1.3,5)\n",
    "    if(len(faces) == 0):\n",
    "        return image, []\n",
    "    \n",
    "    for (x1, y1, x2, y2) in faces:\n",
    "        cv2.rectangle(image, (x1, y1), (x1+x2, y1+y2),(0, 0, 200), 2)\n",
    "        roi = image[y1:y1+y2, x1:x1+x2]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return image, roi\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face_roi = face_detector(frame)\n",
    "    try:\n",
    "        face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # results contains tuple of label and confidence value\n",
    "        results = face_recog_model.predict(face_roi)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int(100 * (1 - (results[1])/ 350))     # gets confidence in percentage\n",
    "            display_string = str(confidence) + \"% Confident it is user\"\n",
    "        \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_DUPLEX, 1,\n",
    "                   (200, 0, 0), 1)\n",
    "        \n",
    "        if confidence > 77:\n",
    "            cv2.putText(image, \"Face Recognised, device unlocked\", (250, 450), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                   (200, 0, 0), 2)\n",
    "            cv2.imshow(\"Face Recognition Software\", image)\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                   (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Face Recognition Software\", image)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, \"No face found\", (220, 120), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                   (0, 0, 255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                   (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Face Recognition Software\", image)\n",
    "        pass\n",
    "    \n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
