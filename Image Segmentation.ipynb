{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of contours found: 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"D:\\Computer_Vision_Recap\\images/shapes.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edged  = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "# finding contours in image\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(\"Num of contours found: \" + str(len(contours)))\n",
    "\n",
    "# draws all contours, -1 as 3rd param draws all\n",
    "cv2.drawContours(image, contours, -1, (255, 0, 0), 3)\n",
    "\n",
    "cv2.imshow(\"Contours\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Sorting Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of contours found: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"D:\\Computer_Vision_Recap\\images/BunchOfShapes.jpg\")\n",
    "height, width, color = image.shape\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edged  = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "# black canvas for showing contours\n",
    "black_canvas = np.zeros((height, width, 3),dtype =\"uint8\")\n",
    "\n",
    "# finding contours in image\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(\"Num of contours found: \" + str(len(contours)))\n",
    "\n",
    "# draws all contours, -1 as 3rd param draws all on normal image\n",
    "cv2.drawContours(image, contours, -1, (255, 0, 0), 3)\n",
    "# draw contours on black_cavas\n",
    "cv2.drawContours(black_canvas, contours, -1, (255, 0, 0), 3)\n",
    "\n",
    "cv2.imshow(\"Contours\", black_canvas)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contour areas b4 sort: [15581.0, 14012.0, 45142.0, 28269.0]\n",
      "The contour areas after sorting: [45142.0, 28269.0, 15581.0, 14012.0]\n"
     ]
    }
   ],
   "source": [
    "# ssorting contours by size or area\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# func to display contour area and ret area of all contours as list\n",
    "def get_contour_areas(contours):\n",
    "    all_areas = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)      # gets area of the contour\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "# black canvas for showing contours\n",
    "black_canvas = np.zeros((height, width, 3),dtype =\"uint8\")\n",
    "\n",
    "# contour areas b4 sort\n",
    "print(\"The contour areas b4 sort: \" + str(get_contour_areas(contours)))\n",
    "\n",
    "# sort contours large to small\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "# contour areas after sorting\n",
    "print(\"The contour areas after sorting: \" + str(get_contour_areas(sorted_contours)))\n",
    "\n",
    "\n",
    "# iterate through contours and draw one by one\n",
    "for i, cnt in enumerate(sorted_contours):\n",
    "    cv2.drawContours(black_canvas, [cnt], -1, (0, 255, 0), 3)\n",
    "    cv2.imshow(\"Contour by area for contour: {0}\".format(i+1), black_canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting contours from left to right\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    # func used to sorts contour by pos & ret X cord of send centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)             # gets center point of the contours in bracket\n",
    "        return (int(M[\"m10\"]/M[\"m00\"]))\n",
    "    \n",
    "def label_contour_center(image, contours):\n",
    "    # places blue circle on centroid of contours\n",
    "    M = cv2.moments(contours)\n",
    "    cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "    cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "    \n",
    "    # draw the circle on centroid\n",
    "    cv2.circle(image, (cx, cy), 10, (255, 0, 0), -1)\n",
    "    return image\n",
    "\n",
    "\n",
    "# loads image and creates the black_canvas\n",
    "image = cv2.imread(\"D:\\Computer_Vision_Recap\\images/BunchOfShapes.jpg\")\n",
    "original_image = image.copy()\n",
    "height, width, color = image.shape\n",
    "black_canvas = np.zeros((height, width, 3),dtype =\"uint8\")\n",
    "\n",
    "\n",
    "# computers center of mass or centroid and draw on image\n",
    "for i, c in enumerate(contours):\n",
    "    orig = label_contour_center(image, c)\n",
    "\n",
    "cv2.imshow(\"contour Centers \", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# sorts contours from left to right using x_cord_contour func\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse=False)\n",
    "\n",
    "# Labels contour from left to right\n",
    "for i, contour in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(black_canvas, [contour], -1, (255, 0, 0), 3)\n",
    "    M = cv2.moments(contour)\n",
    "    cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "    cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "    cv2.putText(black_canvas, str(i+1), (cx-5, cy-5), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"Sorted from left to right\", black_canvas)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # gets bounding box housing the contours\n",
    "    (x1, y1, x2, y2) = cv2.boundingRect(contour)\n",
    "    # crop each contour and save to disk\n",
    "    cropped_contour = original_image[y1:y1 + y2, x1:x1 + x2]\n",
    "    image_name = \"output_shape_number \" + str(i+1) + \".jpg\"\n",
    "    cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### Approximating Contours and Convex Hull\n",
    "* approx contour shape better rather than just use bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# load image and keep a copy\n",
    "image = cv2.imread(\"D:\\Computer_Vision_Recap\\images/House.jpg\")\n",
    "orig_image = image.copy()\n",
    "\n",
    "# grayscales and bin image\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray_image, 125, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# finds contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# iterate through each contour and get bounding box\n",
    "for contour in contours:\n",
    "    x1, y1, x2, y2 = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(orig_image, (x1, y1), (x1+x2, y1+y2), (255, 0, 0), 2)\n",
    "    cv2.imshow(\"Bounding box\", orig_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "\n",
    "# iterate through each contour and get approx contour\n",
    "for contour in contours:\n",
    "    # calc accuracy as % of contour perimeter\n",
    "    accuracy = 0.01* cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, accuracy, True)\n",
    "    cv2.drawContours(image, [approx], 0, (225, 0, 0), 2)\n",
    "    cv2.imshow(\"Approx Poly Dp\", image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convex Hull(smallest polygon that can fit around object)\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"D:\\Computer_Vision_Recap\\images/Star.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# thresh image and find contours\n",
    "ret, thresh = cv2.threshold(gray_image, 170, 255, 0)\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# sorts contour by area and removes largest frame contour that's the image frame\n",
    "n = len(contours) - 1\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# iterates through contours and draw the convex hull\n",
    "for contour in contours:\n",
    "    hull = cv2.convexHull(contour)\n",
    "    cv2.drawContours(image, [hull], 0, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"Convex Hull\", image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Matching Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29032591427461973\n",
      "0.35307680545737763\n",
      "0.30181643676514236\n",
      "0.2735596255305207\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load shape to identify in list\n",
    "template = cv2.imread(\"D:\\Computer_Vision_Recap\\images/Star_2.jpg\", 0)\n",
    "# loads the list of shapes\n",
    "target = cv2.imread(\"D:\\Computer_Vision_Recap\\images/Shapes_to_match.jpg\")\n",
    "target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# theresh both images to remove noise\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "# finds and sort contours of template and remove largest contour, i.e image outline by xtracting  2nd largest\n",
    "contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse=True)\n",
    "template_contour = sorted_contours[1]       # gets 2nd largest contour\n",
    "\n",
    "\n",
    "# gets contours of target list\n",
    "target_contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in target_contours:\n",
    "    # iterate through each contour in target and match with template contour\n",
    "    match = cv2.matchShapes(template_contour, contour, 1, 0.0)\n",
    "    print(match)\n",
    "    if match < 0.30:      # the lesser the match value the more similar it is\n",
    "        closest_contour = contour\n",
    "    else:\n",
    "        closest_contour = []\n",
    "\n",
    "# draws contour over image that matches in list\n",
    "cv2.drawContours(target, [closest_contour], -1, (0, 0, 255), 3)\n",
    "cv2.imshow(\"matched_object\", target)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Detection\n",
    "* Hough Lines\n",
    "* Probablisitic Hough Lines\n",
    "\n",
    "n.b: Not performing well yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line detection using Hough Lines\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"D:/Computer_Vision_Recap/images/soduku.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(gray_image, 20, 100, 0)\n",
    "edges = cv2.Canny(gray_image, 100, 150, apertureSize = 3)\n",
    "\n",
    "# get line using HoughLines\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 250)\n",
    "\n",
    "# iterate through the lines detected in houghline format and change to cv.lines format\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Hough_Line Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Using Probablistic HoughLines\n",
    "image = cv2.imread(\"D:/Computer_Vision_Recap/images/sudoku_2.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(gray_image, 20, 100, 0)\n",
    "edges = cv2.Canny(gray_image, 100, 170, apertureSize = 3)\n",
    "\n",
    "\n",
    "# gets line using Probablistic HoughLine detection\n",
    "lines = cv2.HoughLinesP(edges, 3, np.pi / 180, 350, 5, 7)\n",
    "print(lines.shape)\n",
    "\n",
    "# no need for preprocessing result here\n",
    "for line in lines[0]:\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
    "    \n",
    "cv2.imshow(\"Probablistic Hough_Line Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### BlobDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"D:/Computer_Vision_Recap/images/sunflower.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create()       # init the detector\n",
    "keypoints = detector.detect(gray_image)          # detects blobs\n",
    "\n",
    "# draw detected blobs, n.b: cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "# ensures size of circle is actual sixe of blob\n",
    "\n",
    "blank = np.zeros((1,1), np.uint8)\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0, 255, 0),\n",
    "                         cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"Blob Detection\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
